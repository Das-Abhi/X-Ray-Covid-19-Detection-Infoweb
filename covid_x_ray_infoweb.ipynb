{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzcGP-o07ANA",
    "outputId": "db75cf99-df47-4a12-f6e9-dfd17473e486",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: Too many arguments.\n",
      "\n",
      "usage: git clone [<options>] [--] <repo> [<dir>]\n",
      "\n",
      "    -v, --verbose         be more verbose\n",
      "    -q, --quiet           be more quiet\n",
      "    --progress            force progress reporting\n",
      "    -n, --no-checkout     don't create a checkout\n",
      "    --bare                create a bare repository\n",
      "    --mirror              create a mirror repository (implies bare)\n",
      "    -l, --local           to clone from a local repository\n",
      "    --no-hardlinks        don't use local hardlinks, always copy\n",
      "    -s, --shared          setup as shared repository\n",
      "    --recurse-submodules[=<pathspec>]\n",
      "                          initialize submodules in the clone\n",
      "    --recursive ...       alias of --recurse-submodules\n",
      "    -j, --jobs <n>        number of submodules cloned in parallel\n",
      "    --template <template-directory>\n",
      "                          directory from which templates will be used\n",
      "    --reference <repo>    reference repository\n",
      "    --reference-if-able <repo>\n",
      "                          reference repository\n",
      "    --dissociate          use --reference only while cloning\n",
      "    -o, --origin <name>   use <name> instead of 'origin' to track upstream\n",
      "    -b, --branch <branch>\n",
      "                          checkout <branch> instead of the remote's HEAD\n",
      "    -u, --upload-pack <path>\n",
      "                          path to git-upload-pack on the remote\n",
      "    --depth <depth>       create a shallow clone of that depth\n",
      "    --shallow-since <time>\n",
      "                          create a shallow clone since a specific time\n",
      "    --shallow-exclude <revision>\n",
      "                          deepen history of shallow clone, excluding rev\n",
      "    --single-branch       clone only one branch, HEAD or --branch\n",
      "    --no-tags             don't clone any tags, and make later fetches not to follow them\n",
      "    --shallow-submodules  any cloned submodules will be shallow\n",
      "    --separate-git-dir <gitdir>\n",
      "                          separate git dir from working tree\n",
      "    -c, --config <key=value>\n",
      "                          set config inside the new repository\n",
      "    --server-option <server-specific>\n",
      "                          option to transmit\n",
      "    -4, --ipv4            use IPv4 addresses only\n",
      "    -6, --ipv6            use IPv6 addresses only\n",
      "    --filter <args>       object filtering\n",
      "    --remote-submodules   any cloned submodules will use their remote-tracking branch\n",
      "    --sparse              initialize sparse-checkout file to include only files at root\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! git clone github.com/Das-Abhi/covid-detection-x-ray.git # for dataset, it is a private repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xFXkvLgmDjI6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1aec479d0c53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "#Model\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model,load_model\n",
    "from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPooling2D,MaxPool2D,AveragePooling2D,GlobalMaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping,ModelCheckpoint\n",
    "from keras.metrics import PrecisionAtRecall,Recall \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#Model Analysis\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cYiDs4TDzVK"
   },
   "outputs": [],
   "source": [
    "path = '/content/covid-detection-x-ray/COVID-19_Radiography_Dataset/'\n",
    "\n",
    "diag_code_dict = {\n",
    "    'COVID': 0,\n",
    "    'Lung_Opacity': 1,\n",
    "    'Normal': 2,\n",
    "    'Viral Pneumonia': 3}\n",
    "\n",
    "diag_title_dict = {\n",
    "    'COVID': 'Covid-19',\n",
    "    'Lung_Opacity': 'Lung Opacity',\n",
    "    'Normal': 'Healthy',\n",
    "    'Viral Pneumonia': 'Viral Pneumonia'}\n",
    "\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in glob(os.path.join(path, '*','*.png'))}\n",
    "\n",
    "covidData = pd.DataFrame.from_dict(imageid_path_dict, orient = 'index').reset_index()\n",
    "covidData.columns = ['image_id','path']\n",
    "classes = covidData.image_id.str.split('-').str[0]\n",
    "covidData['diag'] = classes\n",
    "covidData['target'] = covidData['diag'].map(diag_code_dict.get) \n",
    "covidData['Class'] = covidData['diag'].map(diag_title_dict.get) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-DUcyiAEA4k",
    "outputId": "e067cbd4-e34d-422c-c467-498b8383bb9d"
   },
   "outputs": [],
   "source": [
    "samples,features = covidData.shape\n",
    "duplicated = covidData.duplicated().sum()\n",
    "null_values = covidData.isnull().sum().sum()\n",
    "\n",
    "print('Basic EDA')\n",
    "print('Number of samples: %d'%(samples))\n",
    "print('Number of duplicated values: %d'%(duplicated))\n",
    "print('Number of Null samples: %d' % (null_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "A80aHP9LEDab",
    "outputId": "61f732ac-77fd-4c90-f109-82ad7b5b1400"
   },
   "outputs": [],
   "source": [
    "#Samples per class\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.set(style=\"ticks\", font_scale = 1)\n",
    "ax = sns.countplot(data = covidData,x='Class',order = covidData['Class'].value_counts().index,palette=\"flare\")\n",
    "sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "plt.xticks(rotation=0,fontsize = 12)\n",
    "ax.set_xlabel('Sample Type - Diagnosis',fontsize = 14,weight = 'bold')\n",
    "ax.set(yticklabels=[])\n",
    "ax.axes.get_yaxis().set_visible(False) \n",
    "plt.title('Number of Samples per Class', fontsize = 16,weight = 'bold');\n",
    "#Plot numbers\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\"%.1f%%\" % (100*float(p.get_height()/samples)), (p.get_x() + p.get_width() / 2., abs(p.get_height())),\n",
    "    ha='center', va='bottom', color='black', xytext=(0, 10),rotation = 'horizontal',\n",
    "    textcoords='offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN_7Bfa_EFbu"
   },
   "outputs": [],
   "source": [
    "covidData['image'] = covidData['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "lbnXwXGREORg",
    "outputId": "d7a4a9fe-6447-4ef3-9640-640b5f68868b"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "pic_id = random.randrange(0, samples)\n",
    "picture = covidData['path'][pic_id]\n",
    "image = cv2.imread(picture)\n",
    "plt.imshow(image)\n",
    "plt.axis('off');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scZ7OcY4Ebyu"
   },
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-wlPOVDwEX0Q",
    "outputId": "216dd4f0-405b-42b7-f702-2537a2265f5d"
   },
   "outputs": [],
   "source": [
    "#add the path general where the classes subpath are allocated\n",
    "path = '/content/covid-detection-x-ray/COVID-19_Radiography_Dataset'\n",
    "\n",
    "classes=[\"COVID\", \"Lung_Opacity\", \"Normal\", \"Viral Pneumonia\"]\n",
    "#classes=[\"COVID\",  \"Normal\"]\n",
    "num_classes = len(classes)\n",
    "batch_size=32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "\n",
    "#load the images to training\n",
    "train_generator = train_datagen.flow_from_directory(directory=path, \n",
    "                                              target_size=(299, 299),\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training',\n",
    "                                              shuffle=True, classes=classes,\n",
    "                                              batch_size=batch_size, \n",
    "                                              color_mode=\"grayscale\")\n",
    "#load the images to test\n",
    "validation_generator = val_datagen.flow_from_directory(directory=path, \n",
    "                                              target_size=(299, 299),\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='validation',\n",
    "                                              shuffle=False, classes=classes,\n",
    "                                              batch_size=batch_size, \n",
    "                                              color_mode=\"grayscale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zTn2q5yE4bH"
   },
   "source": [
    "### Model-1 Resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuXso-MKEtmB",
    "outputId": "ad49d03c-adff-444a-e023-5038152a4f3f"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(include_top=False,weights='imagenet',pooling='avg')\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(3,(3,3), padding='same', input_shape=(224,224,1)),\n",
    "  base_model,\n",
    "  Dense(4, activation='softmax'),\n",
    "])\n",
    "opt = Adam(lr=0.0005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5P5KHq-E8UH",
    "outputId": "cf43406e-107a-4f4b-f627-e0b09d1f931a"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=0.00001, mode='auto')\n",
    "checkpoint = ModelCheckpoint(\"model_weights1.h5\", monitor='val_accuracy',\n",
    "                             save_weights_only=True, mode='max', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "callbacks = [checkpoint, reduce_lr,early_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = validation_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwDFbz9tTiF7"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "dgx9Sz6UUPmH",
    "outputId": "fc867927-5df0-4791-d06e-573cd223fbb8"
   },
   "outputs": [],
   "source": [
    "predictions = np.array(list(map(lambda x: np.argmax(x), y_pred)))\n",
    "y_true=validation_generator.classes\n",
    "CMatrix = pd.DataFrame(confusion_matrix(y_true, predictions), columns=classes, index =classes)\n",
    "len(y_true)\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.heatmap(CMatrix, annot = True, fmt = 'g' ,vmin = 0, vmax = 250,cmap = 'Blues')\n",
    "ax.set_xlabel('Predicted',fontsize = 14,weight = 'bold')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation =0);\n",
    "\n",
    "ax.set_ylabel('Actual',fontsize = 14,weight = 'bold') \n",
    "ax.set_yticklabels(ax.get_yticklabels(),rotation =0);\n",
    "ax.set_title('Confusion Matrix - Test Set',fontsize = 16,weight = 'bold',pad=20);\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DghpeqidFLUX",
    "outputId": "850ffd3c-9e15-4df6-d982-18a1d7ba8d22"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_true, predictions)\n",
    "results_all = precision_recall_fscore_support(y_true, predictions, average='macro',zero_division = 1)\n",
    "results_class = precision_recall_fscore_support(y_true, predictions, average=None, zero_division = 1)\n",
    "\n",
    "metric_columns = ['Precision','Recall', 'F-Score','S']\n",
    "all_df = pd.concat([pd.DataFrame(list(results_class)).T,pd.DataFrame(list(results_all)).T])\n",
    "all_df.columns = metric_columns\n",
    "all_df.index = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia','Total']\n",
    "\n",
    "def metrics_plot(df,metric):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    ax = sns.barplot(data =df, x=df.index, y = metric,palette = \"Blues_d\")\n",
    "    #Bar Labels\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(\"%.1f%%\" % (100*p.get_height()), (p.get_x() + p.get_width() / 2., abs(p.get_height())),\n",
    "        ha='center', va='bottom', color='black', xytext=(-3, 5),rotation = 'horizontal',textcoords='offset points')\n",
    "    sns.despine(top=True, right=True, left=True, bottom=False)\n",
    "    ax.set_xlabel('Class',fontsize = 14,weight = 'bold')\n",
    "    ax.set_ylabel(metric,fontsize = 14,weight = 'bold')\n",
    "    ax.set(yticklabels=[])\n",
    "    ax.axes.get_yaxis().set_visible(False) \n",
    "    plt.title(metric+ ' Results per Class', fontsize = 16,weight = 'bold');\n",
    "    \n",
    "metrics_plot(all_df, 'Precision')\n",
    "metrics_plot(all_df, 'Recall')\n",
    "metrics_plot(all_df, 'F-Score')\n",
    "print('**Overall Results**')\n",
    "print('Accuracy Result: %.2f%%'%(acc*100))\n",
    "print('Precision Result: %.2f%%'%(all_df.iloc[4,0]*100))\n",
    "print('Recall Result: %.2f%%'%(all_df.iloc[4,1]*100))\n",
    "print('F-Score Result: %.2f%%'%(all_df.iloc[4,2]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQhnyqAdTBX9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "covid_x_ray_Fiver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
